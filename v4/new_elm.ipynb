{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELM + Kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccinfo değeri bulunamadığı için silinecek satır sayısı: 15\n",
      "Kümeleme işlemi tamamlandı. Küme dağılımı:\n",
      "1    521\n",
      "0    391\n",
      "3    361\n",
      "2    301\n",
      "4    118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 0 için model eğitimi başlatılıyor...\n",
      "Cluster 0 sonuçları:\n",
      "MAE: 0.5412\n",
      "MAPE: 0.1224\n",
      "R2: -1.5683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1429\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[1;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1429\u001b[0m     \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m casted\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: value array of shape (391,1) could not be broadcast to indexing result of shape (391,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# Bu kümedeki tahminleri orijinal indeksleriyle saklıyoruz\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mall_predictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_mask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y_pred_cluster\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTüm kümeler için model sonuçları:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(cluster_metrics)\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\indexing.py:1944\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1944\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\indexing.py:2218\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_check_is_chained_assignment_possible()\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;66;03m# actually do the set\u001b[39;00m\n\u001b[1;32m-> 2218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\internals\\managers.py:415\u001b[0m, in \u001b[0;36mBaseBlockManager.setitem\u001b[1;34m(self, indexer, value, warn)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# No need to split if we either set all columns or on a single block\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# manager\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetitem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\yagiz\\anaconda3\\envs\\img\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1432\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[1;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_list_like(casted):\n\u001b[1;32m-> 1432\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1433\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetting an array element with a sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1434\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# -------------------------\n",
    "# HPELM Kullanılarak Scikit-Learn Uyumlu ELMRegressor Wrapper'ı\n",
    "# -------------------------\n",
    "from hpelm import ELM as HPELM\n",
    "\n",
    "class HPELMRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_hidden=50, activation='sigmoid', random_state=42):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.activation = activation\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Pandas DataFrame veya Series ise numpy array'e dönüştür\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        if hasattr(y, 'values'):\n",
    "            y = y.values\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        # y eğer tek boyutlu ise n_out = 1, aksi halde y.shape[1] olarak ayarlanıyor.\n",
    "        n_out = 1 if y.ndim == 1 else y.shape[1]\n",
    "        # Eğer random_state verilmişse, NumPy random seed'i ayarlanıyor.\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        # HPELM modelini oluşturuyoruz; random_state parametresi kullanılmıyor.\n",
    "        self.model_ = HPELM(n_features, n_out, classification='regression')\n",
    "        # Seçilen aktivasyon fonksiyonuna göre n_hidden nöron ekleniyor.\n",
    "        self.model_.add_neurons(self.n_hidden, self.activation)\n",
    "        # Model eğitim verileri ile eğitiliyor. 'r' parametresi regresyon için kullanılır.\n",
    "        self.model_.train(X, y, 'r')\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "# -------------------------\n",
    "# Ön İşlem ve Veri Hazırlığı\n",
    "# -------------------------\n",
    "# Veri setini yükleyip gereksiz sütunları kaldırıyoruz.\n",
    "df = pd.read_excel(\"dataset.xlsx\")\n",
    "df.drop(columns=[\"Seli\", \"Tarih\"], inplace=True, errors='ignore')\n",
    "\n",
    "# mccinfo sütunundan dört haneli değeri çekmek için fonksiyon\n",
    "def extract_mcc(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    match = re.match(r\"(\\d{4})-\", value)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['mccinfo'] = df['mccinfo'].apply(extract_mcc)\n",
    "num_missing_mcc = df['mccinfo'].isnull().sum()\n",
    "print(f\"mccinfo değeri bulunamadığı için silinecek satır sayısı: {num_missing_mcc}\")\n",
    "df = df.dropna(subset=['mccinfo'])\n",
    "\n",
    "# Sayısal sütunlardaki değerlerin düzenlenmesi\n",
    "numeric_columns = [\n",
    "    \"bıst100_Kapanış\", \"bıst100_Açılış\", \"bıst100_Yüksek\", \"bıst100_Düşük\",\n",
    "    \"Euro_Kapanış\", \"Euro_Açılış\", \"Euro_Yüksek\", \"Euro_Düşük\",\n",
    "    \"USD_Kapanış\", \"USD_Açılış\", \"USD_Yüksek\", \"USD_Düşük\",\n",
    "]\n",
    "\n",
    "def fix_numeric_value(s):\n",
    "    s = s.replace(',', '.')\n",
    "    if s.count('.') > 1:\n",
    "        second_dot = s.find('.', s.find('.') + 1)\n",
    "        s = s[:second_dot]\n",
    "    return s\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(str).apply(fix_numeric_value)\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# Kategorik sütunların kodlanması\n",
    "categorical_columns = [\"Şehir\", \"İlçe\", \"mccinfo\"]\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Hedef ve özniteliklerin ayrılması\n",
    "target = \"Tek Çekim Komisyon Oranı (Güncel)\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# -------------------------\n",
    "# Ölçeklendirme (Scaler Uygulaması)\n",
    "# -------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "# -------------------------\n",
    "# Kümeleme İşlemi (KMeans)\n",
    "# -------------------------\n",
    "n_clusters = 5  # Küme sayısı\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "# Küme bilgilerini ölçeklendirilmiş veri setine ekliyoruz.\n",
    "X_scaled['Cluster'] = clusters\n",
    "\n",
    "print(\"Kümeleme işlemi tamamlandı. Küme dağılımı:\")\n",
    "print(pd.Series(clusters).value_counts())\n",
    "\n",
    "# -------------------------\n",
    "# Küme Bazında Model Eğitimi, Tahmin ve Metrik Hesaplaması (HPELMRegressor, Feature Selection olmadan)\n",
    "# -------------------------\n",
    "all_predictions = pd.Series(index=y.index, dtype=float)\n",
    "cluster_metrics = {}\n",
    "\n",
    "for cluster in np.unique(clusters):\n",
    "    print(f\"\\nCluster {cluster} için model eğitimi başlatılıyor...\")\n",
    "    # İlgili kümeye ait verileri seçip 'Cluster' sütununu çıkarıyoruz\n",
    "    cluster_mask = X_scaled['Cluster'] == cluster\n",
    "    X_cluster = X_scaled.loc[cluster_mask].drop(columns=['Cluster'])\n",
    "    y_cluster = y.loc[cluster_mask]\n",
    "    \n",
    "    # Eğer örnek sayısı 10'dan azsa, CV kat sayısı örnek sayısına göre ayarlanıyor\n",
    "    if len(X_cluster) < 10:\n",
    "        print(f\"Uyarı: Cluster {cluster} için örnek sayısı {len(X_cluster)}, CV kat sayısı örnek sayısına göre ayarlanıyor.\")\n",
    "        kf = KFold(n_splits=len(X_cluster), shuffle=True, random_state=123)\n",
    "    else:\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Pipeline: sadece HPELMRegressor kullanılıyor (özellik seçimi olmadan)\n",
    "    pipeline = Pipeline([\n",
    "        ('elm', HPELMRegressor(n_hidden=50, activation='tanh', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation ile tahminleri elde ediyoruz\n",
    "    y_pred_cluster = cross_val_predict(pipeline, X_cluster, y_cluster, cv=kf)\n",
    "    \n",
    "    # Küme bazında performans metriklerini hesaplıyoruz\n",
    "    mae = mean_absolute_error(y_cluster, y_pred_cluster)\n",
    "    mape = mean_absolute_percentage_error(y_cluster, y_pred_cluster)\n",
    "    r2 = r2_score(y_cluster, y_pred_cluster)\n",
    "    \n",
    "    cluster_metrics[cluster] = {'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
    "    print(f\"Cluster {cluster} sonuçları:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    \n",
    "    # Bu kümedeki tahminleri orijinal indeksleriyle saklıyoruz\n",
    "    all_predictions.loc[cluster_mask] = y_pred_cluster\n",
    "\n",
    "print(\"\\nTüm kümeler için model sonuçları:\")\n",
    "print(cluster_metrics)\n",
    "\n",
    "# -------------------------\n",
    "# Genel Performans Metriklerinin Hesaplanması\n",
    "# -------------------------\n",
    "overall_mae = mean_absolute_error(y, all_predictions)\n",
    "overall_mape = mean_absolute_percentage_error(y, all_predictions)\n",
    "overall_r2 = r2_score(y, all_predictions)\n",
    "\n",
    "print(\"\\nGenel model sonuçları:\")\n",
    "print(f\"Genel MAE: {overall_mae:.4f}\")\n",
    "print(f\"Genel MAPE: {overall_mape:.4f}\")\n",
    "print(f\"Genel R2: {overall_r2:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Gerçek ve Tahmin Edilen Değerlerin Görselleştirilmesi\n",
    "# -------------------------\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.scatter(np.arange(len(y)), y, label=\"Gerçek Değerler\", marker=\"o\")\n",
    "plt.plot(np.arange(len(y)), all_predictions.sort_index(), label=\"Tahmin Edilen Değerler\", marker=\"x\", color=\"red\", linestyle=\"-\")\n",
    "plt.xlabel(\"Örnek Index\")\n",
    "plt.ylabel(\"Değer\")\n",
    "plt.title(\"Gerçek ve Tahmin Edilen Değerler (Feature Selection olmadan, KMeans + HPELMRegressor)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
